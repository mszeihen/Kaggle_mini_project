{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first few section is dedicated to preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_csv(filename,id_array,label_array):\n",
    "    data = np.column_stack((id_array, label_array))\n",
    "    df = pd.DataFrame(data, columns=['id', 'label'])\n",
    "    df['id'] = df['id'].astype(int)\n",
    "    df.to_csv(\"./output/\"+filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAINING_DATA = \"./data/train.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90524101</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>20.66</td>\n",
       "      <td>117.80</td>\n",
       "      <td>991.7</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.13040</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.088240</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080</td>\n",
       "      <td>25.41</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.33010</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.08503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89346</td>\n",
       "      <td>B</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.40</td>\n",
       "      <td>56.36</td>\n",
       "      <td>246.3</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>0.03116</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>...</td>\n",
       "      <td>9.699</td>\n",
       "      <td>20.07</td>\n",
       "      <td>60.90</td>\n",
       "      <td>285.5</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.05232</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.07804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902975</td>\n",
       "      <td>B</td>\n",
       "      <td>12.21</td>\n",
       "      <td>14.09</td>\n",
       "      <td>78.78</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.07823</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>...</td>\n",
       "      <td>13.130</td>\n",
       "      <td>19.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>529.9</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.24310</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904969</td>\n",
       "      <td>B</td>\n",
       "      <td>12.34</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "      <td>469.1</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.04571</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>...</td>\n",
       "      <td>13.180</td>\n",
       "      <td>16.85</td>\n",
       "      <td>84.11</td>\n",
       "      <td>533.1</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.06744</td>\n",
       "      <td>0.04921</td>\n",
       "      <td>0.04793</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.05974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id label  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  90524101     M        17.99         20.66          117.80      991.7   \n",
       "1  84358402     M        20.29         14.34          135.10     1297.0   \n",
       "2     89346     B         9.00         14.40           56.36      246.3   \n",
       "3    902975     B        12.21         14.09           78.78      462.0   \n",
       "4    904969     B        12.34         14.95           78.29      469.1   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.10360           0.13040        0.120100             0.088240   \n",
       "1          0.10030           0.13280        0.198000             0.104300   \n",
       "2          0.07005           0.03116        0.003681             0.003472   \n",
       "3          0.08108           0.07823        0.068390             0.025340   \n",
       "4          0.08682           0.04571        0.021090             0.020540   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...        21.080          25.41           138.10      1349.0   \n",
       "1  ...        22.540          16.67           152.20      1575.0   \n",
       "2  ...         9.699          20.07            60.90       285.5   \n",
       "3  ...        13.130          19.29            87.65       529.9   \n",
       "4  ...        13.180          16.85            84.11       533.1   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.14820            0.37350          0.33010               0.19740   \n",
       "1           0.13740            0.20500          0.40000               0.16250   \n",
       "2           0.09861            0.05232          0.01472               0.01389   \n",
       "3           0.10260            0.24310          0.30760               0.09140   \n",
       "4           0.10480            0.06744          0.04921               0.04793   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.3060                  0.08503  \n",
       "1          0.2364                  0.07678  \n",
       "2          0.2991                  0.07804  \n",
       "3          0.2677                  0.08824  \n",
       "4          0.2298                  0.05974  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "label                      0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = \"./data/test.csv\"\n",
    "\n",
    "test = pd.read_csv(TEST_DATA)\n",
    "Test_IDS = test['id'].to_numpy()\n",
    "\n",
    "comp_X_test = test.drop(columns=['id'])\n",
    "comp_X_test_scaled = scaler.fit_transform(comp_X_test.to_numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=['id','label']).values #feature columns\n",
    "Y_train = data['label'].values #classification label\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training a perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(X_train_scaled, Y_train)\n",
    "y_pred = perceptron_model.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = perceptron_model.predict(comp_X_test.to_numpy())\n",
    "create_sample_csv(f\"perceptron_model_{int(accuracy*100)}.csv\",Test_IDS,y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560439560439561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "\n",
    "logistic_regression_model.fit(X_train_scaled, Y_train)\n",
    "y_pred = logistic_regression_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = logistic_regression_model.predict(comp_X_test_scaled)\n",
    "create_sample_csv(f\"LogisticRegression_model_{int(accuracy*100)}.csv\",Test_IDS,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978021978021978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_scaled, Y_train)\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = svm_classifier.predict(comp_X_test_scaled)\n",
    "create_sample_csv(f\"SVM_model_{int(accuracy*100)}.csv\",Test_IDS, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9120879120879121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "decision_tree_classifier.fit(X_train, Y_train)\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = decision_tree_classifier.predict(comp_X_test.to_numpy())\n",
    "create_sample_csv(f\"DecisionTree_model_{int(accuracy*100)}.csv\",Test_IDS,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989010989010989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train_scaled, Y_train)\n",
    "y_pred = knn_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = knn_classifier.predict(comp_X_test_scaled)\n",
    "create_sample_csv(f\"KNN_model_{int(accuracy*100)}.csv\",Test_IDS,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.967032967032967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "random_forest_classifier.fit(X_train, Y_train)\n",
    "y_pred = random_forest_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = random_forest_classifier.predict(comp_X_test.to_numpy())\n",
    "create_sample_csv(f\"RandomForest_model_{int(accuracy*100)}.csv\",Test_IDS,y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
